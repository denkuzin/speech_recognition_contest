{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#import matplotlib; matplotlib.use('Agg')\n",
    "\n",
    "#cache files\n",
    "#ls | parallel -L50 \"vmtouch -t {}\"\n",
    "\n",
    "\n",
    "import os\n",
    "from os.path import isdir, join, basename, dirname\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Math\n",
    "import numpy as np\n",
    "from scipy.fftpack import fft\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import IPython.display as ipd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", module=\"matplotlib\")\n",
    "warnings.filterwarnings(\"ignore\", module=\"scipy.io\")\n",
    "\n",
    "from sklearn import model_selection\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "import wave\n",
    "import speechpy\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from sklearn import model_selection\n",
    "from matplotlib import pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "\n",
    "import gc\n",
    "import datetime\n",
    "import sys\n",
    "\n",
    "from utils import logger, send2telegramm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SETTINGS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ACTIONS:\n",
    "DO_TRAIN = True\n",
    "DO_CUSTOM_PREDICT = False\n",
    "MODEL_PATH_CUSTOM_PREDICT = 'saved_models/cnn_gpu_1' # in case if DO_CUSTOM_PREDICT == True\n",
    "DEBAG = False\n",
    "PRECEED_TRAIN = 'NO'  # YES - upload pretrained model\n",
    "                       # NO -  start new train\n",
    "\n",
    "\n",
    "NUM_FILTERS_CONV_1 = 32  #32\n",
    "NUM_FILTERS_CONV_2 = 64\n",
    "NUM_FILTERS_CONV_3 = 128\n",
    "NUM_READOUT_NEURONS = 1024 #1024\n",
    "\n",
    "KEEP_PROB = 0.99\n",
    "LEARNING_RATE = 1.0e-5   #1.0e-5\n",
    "TEST_SIZE = 0.03     #0.0002\n",
    "BATCH_SIZE = 100\n",
    "N_CLASSES = 30\n",
    "NUM_EPOCHS = 300\n",
    "NUMBER_STEPS = int(64721*NUM_EPOCHS/BATCH_SIZE)\n",
    "if DEBAG:\n",
    "    NUMBER_STEPS = 100\n",
    "\n",
    "preprocessed_version = 'v1'  #if the files of the version are exist, we will not to preprocess them\n",
    "\n",
    "thersold_good_prediction = 0.99999999\n",
    "NUMBER_STEPS_TEST = int(NUMBER_STEPS/2) #bymber of step in \n",
    "AFTER_NUM_STEPS_APPEND_TEST_DATA = int(NUMBER_STEPS/4) #every the number append test date to train\n",
    "\n",
    "date = datetime.date.today().isoformat()\n",
    "model_dir = 'cnn_gpu_2'\n",
    "model_path = join('saved_models', '{}/model_{}'.format(model_dir, date))\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "if PRECEED_TRAIN == 'YES':\n",
    "    saved_model_dir = ''\n",
    "    logger.info('I will upload pretrained model from: {}'.format(saved_model_dir))\n",
    "    if not os.path.exists(saved_model_dir):\n",
    "        sys.exit(\"the prelimenary trained model path doesn't exist\")\n",
    "logger.info('model_path: {}'.format(model_path))\n",
    "\n",
    "logger.info(\"NUM_FILTERS_CONV_1 = {}\".format(NUM_FILTERS_CONV_1))\n",
    "logger.info(\"NUM_FILTERS_CONV_2 = {}\".format(NUM_FILTERS_CONV_2))\n",
    "logger.info(\"NUM_FILTERS_CONV_3 = {}\".format(NUM_FILTERS_CONV_3))\n",
    "logger.info(\"NUM_READOUT_NEURONS = {}\".format(NUM_READOUT_NEURONS))\n",
    "logger.info(\"KEEP_PROB = {}\".format(KEEP_PROB))\n",
    "logger.info(\"LEARNING_RATE = {}\".format(LEARNING_RATE))\n",
    "logger.info(\"TEST_SIZE = {}\".format(TEST_SIZE))\n",
    "logger.info(\"NUM_EPOCHS = {}\".format(NUM_EPOCHS))\n",
    "logger.info(\"NUMBER_STEPS = {}\".format(NUMBER_STEPS))\n",
    "logger.info(\"BATCH_SIZE = {}\".format(BATCH_SIZE))\n",
    "logger.info(\"N_CLASSES = {}\".format(N_CLASSES))\n",
    "logger.info(\"thersold_good_prediction = {}\".format(thersold_good_prediction))\n",
    "logger.info(\"NUMBER_STEPS_TEST = {}\".format(NUMBER_STEPS_TEST))\n",
    "logger.info(\"AFTER_NUM_STEPS_APPEND_TEST_DATA = {}\".format(AFTER_NUM_STEPS_APPEND_TEST_DATA))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_rate(path):\n",
    "    sample_rate, samples = wavfile.read(path)\n",
    "    return sample_rate\n",
    "\n",
    "def get_amplitudes(path):\n",
    "    sample_rate, samples = wavfile.read(path)\n",
    "    return samples\n",
    "\n",
    "def remove_silence_start():\n",
    "    pass\n",
    "\n",
    "def complete_by_const(array, const = 0, req_len = 16000):\n",
    "    if len(array) < req_len:\n",
    "        new = np.array([const]*req_len)\n",
    "        new[:len(array)] = array\n",
    "    elif len(array) > req_len:\n",
    "        new = array[:req_len]\n",
    "    else:\n",
    "        new = array\n",
    "    return new\n",
    "\n",
    "def encodeTarget(y):\n",
    "    temp = np.zeros((y.size, y.max()+1))\n",
    "    temp[np.arange(y.size), y] = 1\n",
    "    return temp.astype(int)\n",
    "\n",
    "def preprocess_dataframe(df, process_target = True):\n",
    "    global map_dict, map_dict_reverse\n",
    "    df['sample_rate'] = df.train_names.apply(lambda x: get_sample_rate(x))\n",
    "    df['amplitudes'] = df.train_names.apply(lambda x: get_amplitudes(x))\n",
    "    df['avg_ampl'] = df.amplitudes.apply(lambda x: x.mean())\n",
    "    df['std_ampl'] = df.amplitudes.apply(lambda x: x.std())\n",
    "    df['len'] = df.amplitudes.apply(lambda x: len(x))\n",
    "    df['amplitudes'] = df.amplitudes.apply(lambda x: complete_by_const(x))\n",
    "    df['len'] = df.amplitudes.apply(lambda x: len(x))  \n",
    "    if process_target:\n",
    "        uniq_labels = sorted(df.train_labels.unique().tolist())\n",
    "        map_dict = dict(zip(uniq_labels, range(len(uniq_labels))))   # label -> digit\n",
    "        map_dict_reverse = dict((b,a) for a,b in map_dict.items())   # digit -> label\n",
    "        df['encod_label'] = df.train_labels.apply(lambda x : map_dict[x])\n",
    "    return df    \n",
    "      \n",
    "WORKDIR = '/home/dkuzin/files/tensorflow_speech_recognition'\n",
    "\n",
    "train_audio_path = WORKDIR + '/train/audio/'\n",
    "test_audio_path = WORKDIR + '/test/audio/'\n",
    "to_keep = 'yes no up down left right on off stop go silence unknown'.split()    \n",
    "    \n",
    "    \n",
    "path_df_train = 'saved_variables/{}_df_train.pkl'.format(preprocessed_version)\n",
    "path_df_predict = 'saved_variables/{}_df_predict.pkl'.format(preprocessed_version)\n",
    "\n",
    "if (os.path.exists(path_df_train) and os.path.exists(path_df_predict)):\n",
    "    logger.info(\"the data are preprossesed yet, uploading it\")\n",
    "    df_train = pd.read_pickle(path_df_train)\n",
    "    uniq_labels = sorted(df_train.train_labels.unique().tolist())\n",
    "    map_dict = dict(zip(uniq_labels, range(len(uniq_labels))))   # label -> digit\n",
    "    map_dict_reverse = dict((b,a) for a,b in map_dict.items())   # digit -> label\n",
    "    df_predict = pd.read_pickle(path_df_predict)\n",
    "else:    \n",
    "    #read and process train part:\n",
    "    logger.info(\"start to preprocess data\")\n",
    "    dirs = [f for f in os.listdir(train_audio_path) if isdir(join(train_audio_path, f))]\n",
    "    dirs.sort()\n",
    "\n",
    "    train_names = []\n",
    "    for directory in dirs:\n",
    "        directory = join(train_audio_path, directory)\n",
    "        files = [join(directory,f) for f in os.listdir(directory) if f.endswith('.wav')]\n",
    "        train_names.extend(files)\n",
    "    train_names.sort()\n",
    "    train_labels = [f.split('/')[-2] for f in train_names]\n",
    "    user_names = [basename(f).split(\"_\")[0] for f in train_names]\n",
    "    df_train = pd.DataFrame({'train_names':train_names,\n",
    "                       'train_labels':train_labels,\n",
    "                       'user_names':user_names})\n",
    "    df_train = df_train[['train_names', 'user_names','train_labels']]\n",
    "    df_train = df_train[df_train.train_labels != '_background_noise_']\n",
    "    df_train = preprocess_dataframe(df_train, process_target = True)\n",
    "\n",
    "    #read and process predict part:\n",
    "    test_names = [join(test_audio_path, f) for f in os.listdir(test_audio_path) \n",
    "                              if f.endswith('.wav')]\n",
    "    user_names = [basename(f) for f in test_names]\n",
    "    df_predict = pd.DataFrame({'train_names':test_names, 'user_names':user_names})\n",
    "    df_predict = preprocess_dataframe(df_predict, process_target = False)\n",
    "    \n",
    "    df_train.to_pickle(path_df_train)\n",
    "    df_predict.to_pickle(path_df_predict)\n",
    "\n",
    "X = np.vstack(df_train.amplitudes.values)\n",
    "y = df_train.encod_label.values\n",
    "y_binary = encodeTarget(y)\n",
    "\n",
    "X_predict = np.vstack(df_predict.amplitudes.values)\n",
    "\n",
    "logger.info(\"y_binary.shape of train data = {}\".format(y_binary.shape))\n",
    "logger.info(\"X.shape of train data = {}\".format(X.shape))\n",
    "logger.info(\"X_predict.shape of predict data = {}\".format(X_predict.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBAG:\n",
    "#decrease number of elements in training (DELETE IT, for debug only)\n",
    "    X, y, y_binary, df_short = X[::100], y[::100], y_binary[::100], df[::100]\n",
    "    X_predict = X_predict[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(signal):\n",
    "    return speechpy.feature.lmfe(signal, 16000, frame_length=0.02, \n",
    "                frame_stride=0.01, num_filters=40, fft_length=512, low_frequency=0, \n",
    "                high_frequency=None)\n",
    "\n",
    "path_proc_train = 'saved_variables/{}_proc_train.npy'.format(preprocessed_version)\n",
    "path_proc_predict = 'saved_variables/{}_proc_predict.npy'.format(preprocessed_version)\n",
    "\n",
    "if (os.path.exists(path_proc_train) and os.path.exists(path_proc_predict)):\n",
    "    logger.info(\"the PROC data are preprossesed yet, uploading it\")\n",
    "    proc_train = np.load(path_proc_train)\n",
    "    x_test_to_submit = np.load(path_proc_predict)\n",
    "else: \n",
    "    logger.info(\"start to PROC preprocess data\")\n",
    "    t = time.time()\n",
    "    proc_train = np.apply_along_axis(func, 1,X)\n",
    "    logger.info(\"train was transformed, elapsed time is {:.4f} sec\".format(time.time()-t))\n",
    "    t = time.time()\n",
    "    x_test_to_submit = np.apply_along_axis(func, 1, X_predict)\n",
    "    logger.info(\"predict data was transformed, elapsed time is {:.4f} sec\".format(time.time()-t))\n",
    "    \n",
    "    np.save(path_proc_train, proc_train)\n",
    "    np.save(path_proc_predict, x_test_to_submit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = model_selection.train_test_split(\n",
    "                        proc_train, y_binary, test_size = TEST_SIZE)\n",
    "\n",
    "_ = gc.collect()\n",
    "logger.info(\"shapes = X_train {}, y_train {}, X_valid {}, y_valid {}\".format(\n",
    "        X_train.shape, y_train.shape, X_valid.shape, y_valid.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_batch(batch_size):\n",
    "    global data_index\n",
    "    batch = X_train[data_index:data_index+batch_size,:]\n",
    "    labels = y_train[data_index:data_index+batch_size]\n",
    "    data_index = (data_index + batch_size) % (X_train.shape[0])\n",
    "    return (batch, labels)\n",
    "\n",
    "def next_batch_from_test(batch_size, X_add , y_add):\n",
    "    #get next batch\n",
    "    global data_index_test\n",
    "    batch = X_add[data_index_test:data_index_test+batch_size,:]\n",
    "    labels = y_add[data_index_test:data_index_test+batch_size,:]\n",
    "    data_index_test = (data_index_test + batch_size) % (X_add.shape[0])\n",
    "    return (batch, labels)\n",
    "\n",
    "def mark_test_data_and_extract_well_predicted():\n",
    "    #idea:\n",
    "    #if prelimenary trained algo show very high probability a element belong to the class, \n",
    "    # we'll append it to training sample and retrain the algo\n",
    "    logger.info(\"x_test_to_submit.shape = {}\".format(x_test_to_submit.shape))\n",
    "    size = 100\n",
    "    batches_generator = (x_test_to_submit[i:i + size] for i in range(0, len(x_test_to_submit), size))\n",
    "    predictions = []\n",
    "       \n",
    "    for test_batch in batches_generator:\n",
    "        predicted = y_conv.eval(session=sess, feed_dict={x:test_batch, keep_prob: 1.0})\n",
    "        predictions.extend(predicted)\n",
    "    temp_session = tf.Session()\n",
    "    predictions = np.array(predictions)           # to numpy array\n",
    "    predictions = tf.nn.softmax(predictions).eval(session=temp_session)\n",
    "    \n",
    "    predictions = (predictions >= thersold_good_prediction).astype(int) #transform to [0,0,0,1,0,0,]\n",
    "                                                                       #if there is no outstanding value,\n",
    "                                                                       #predicted will consist of zeros\n",
    "    bool_values = np.any(predictions, axis = 1)   # True means there is non-zero element\n",
    "                                                  # False means all elements equal zeros\n",
    "    indexes = np.argwhere(bool_values).ravel()     # indexes of \"True\"\n",
    "    temp_session.close()\n",
    "    return x_test_to_submit[indexes], predictions[indexes]          \n",
    "\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    x = tf.placeholder(tf.float32, shape=[None, 99, 40])  #features\n",
    "    y_ = tf.placeholder(tf.float32, shape=[None, N_CLASSES])  #true targets\n",
    "    \n",
    "    # weight inotialization\n",
    "    def weight_variable(shape):\n",
    "        initial = tf.truncated_normal(shape, mean=0.0, stddev=0.1)   #init by random values ~N(0.0,0.1)\n",
    "        return tf.Variable(initial)\n",
    "\n",
    "    def bias_variable(shape):\n",
    "        initial = tf.constant(0.1, shape=shape)   #init by constant\n",
    "        return tf.Variable(initial)\n",
    "\n",
    "   # First Convolutional Layer  # 5,5\n",
    "    W_conv1 = weight_variable([20, 20, 1, NUM_FILTERS_CONV_1])     #32 maps, tune\n",
    "    b_conv1 = bias_variable([NUM_FILTERS_CONV_1])\n",
    "\n",
    "    x_image = tf.reshape(x, [-1,99,40,1])\n",
    "    #-1 - is the special value, the size of that dimension is computed so that the total size remains constant\n",
    "    #28,28 - width and height\n",
    "    #1 - RGB numbers (we have black and white pics, therefore we have only 1 number)\n",
    "\n",
    "    #convolution layer, activation function and pooling layer\n",
    "    h_conv1 = tf.nn.conv2d(x_image, W_conv1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    h_relu1 = tf.nn.relu(h_conv1 + b_conv1)\n",
    "    h_pool1 = tf.nn.max_pool(h_relu1, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME') #99*40 --> 50*20 \n",
    "    \n",
    "    # second convolutional layer\n",
    "                               #5,5\n",
    "    W_conv2 = weight_variable([10, 10, NUM_FILTERS_CONV_1, NUM_FILTERS_CONV_2])\n",
    "    b_conv2 = bias_variable([NUM_FILTERS_CONV_2])\n",
    "\n",
    "    h_conv2 = tf.nn.conv2d(h_pool1, W_conv2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    h_relu2 = tf.nn.relu(h_conv2 + b_conv2)\n",
    "    h_pool2 = tf.nn.max_pool(h_relu2, ksize=[1, 2, 2, 1],\n",
    "                            strides=[1, 2, 2, 1], padding='SAME') #50*20 --> 25*10   \n",
    "\n",
    "    # third convolutional layer\n",
    "                               #3,3\n",
    "    W_conv3 = weight_variable([5, 5, NUM_FILTERS_CONV_2, NUM_FILTERS_CONV_3])\n",
    "    b_conv3 = bias_variable([NUM_FILTERS_CONV_3])\n",
    "    \n",
    "    h_conv3 = tf.nn.conv2d(h_pool2, W_conv3, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    h_relu3 = tf.nn.relu(h_conv3 + b_conv3)\n",
    "    h_pool3 = tf.nn.max_pool(h_relu3, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME') #25*10 --> 13*5    \n",
    "   \n",
    "   # densely connected layer\n",
    "    W_fc1 = weight_variable([13*5 * NUM_FILTERS_CONV_3, NUM_READOUT_NEURONS])\n",
    "    b_fc1 = bias_variable([NUM_READOUT_NEURONS])\n",
    "\n",
    "    h_pool3_flat = tf.reshape(h_pool3, [-1, 13*5*NUM_FILTERS_CONV_3])\n",
    "    h_fc1 = tf.nn.relu(tf.matmul(h_pool3_flat, W_fc1) + b_fc1) \n",
    "    \n",
    "   # dropout\n",
    "    keep_prob = tf.placeholder(tf.float32)\n",
    "    h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "\n",
    "    # readout layer\n",
    "    W_fc2 = weight_variable([NUM_READOUT_NEURONS, N_CLASSES])\n",
    "    b_fc2 = bias_variable([N_CLASSES])\n",
    "\n",
    "    y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n",
    "    \n",
    "    cross_entropy = tf.reduce_mean(\n",
    "            tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv))\n",
    "    train_step = tf.train.AdamOptimizer(LEARNING_RATE).minimize(cross_entropy)\n",
    "    correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    init = (tf.global_variables_initializer(), tf.local_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Evaluate the Model\n",
    "\n",
    "data_index = 0\n",
    "data_index_test = 0\n",
    "\n",
    "def train():\n",
    "    global stats, sess\n",
    "\n",
    "    num_batches = 200 #every 100 batches collect stats and so on\n",
    "    logger.info(\"num_batches_magic_constant = {}\".format(num_batches))\n",
    "\n",
    "    config=tf.ConfigProto(\n",
    "        intra_op_parallelism_threads=0,\n",
    "        inter_op_parallelism_threads=0,\n",
    "        log_device_placement=True)\n",
    "    config.gpu_options.allow_growth = True\n",
    "\n",
    "    sess = tf.Session(graph=graph, config=config)\n",
    "    _ = sess.run(init)\n",
    "\n",
    "    stats = []\n",
    "    speed = 0\n",
    "    average_loss = 0.\n",
    "    counter = 1\n",
    "    ts = time.time()\n",
    "    average_acc = 0\n",
    "    global_step = 0\n",
    "\n",
    "    if PRECEED_TRAIN == 'YES':\n",
    "        path = saved_model_dir #dirname(model_path)\n",
    "        saver.restore(sess, tf.train.latest_checkpoint(path))       \n",
    "\n",
    "    for i in range(NUMBER_STEPS):\n",
    "        batch = next_batch(BATCH_SIZE)\n",
    "\n",
    "        _, loss_val, acc_val = sess.run([train_step, cross_entropy, accuracy], \n",
    "                    feed_dict={x: batch[0], y_: batch[1], keep_prob: KEEP_PROB})\n",
    "        average_loss += loss_val\n",
    "        average_acc += acc_val\n",
    "\n",
    "        #get and print stats\n",
    "        if i % num_batches == 0 and i != 0:\n",
    "\n",
    "            valid_accuracy = accuracy.eval(\n",
    "                        session=sess, feed_dict={x:X_valid, y_: y_valid, keep_prob: 1.0})\n",
    "            loss_valid = cross_entropy.eval(\n",
    "                        session=sess, feed_dict={x:X_valid, y_: y_valid, keep_prob: 1.0})\n",
    "            average_loss = average_loss/counter\n",
    "            average_acc = average_acc/counter\n",
    "            speed = (counter*BATCH_SIZE)/(time.time() - ts)\n",
    "            stats.append([global_step,average_loss, loss_valid, average_acc,valid_accuracy, speed])\n",
    "            string = \"global_step %d, training/valid loss %.5g\\t%.5g; accuracy %.4g\\t%.4g; speed = %.4g lines/sec\"%(\n",
    "                    global_step, average_loss, loss_valid, average_acc, valid_accuracy, speed)\n",
    "            send2telegramm(string)\n",
    "            logger.info(string)\n",
    "            average_loss, average_acc, counter, ts = 0, 0, 0, time.time()\n",
    "\n",
    "        # append test data to train\n",
    "        if i % AFTER_NUM_STEPS_APPEND_TEST_DATA == 0 and i != 0 :\n",
    "            logger.info(\"start to append TEST data !\")\n",
    "            X_add, y_add = mark_test_data_and_extract_well_predicted()\n",
    "            logger.info(\"X_add.shape = {}\".format(X_add.shape))\n",
    "            for j in range(NUMBER_STEPS_TEST):\n",
    "                batch_test =  next_batch_from_test(BATCH_SIZE, X_add , y_add)\n",
    "                if j%num_batches ==  and j!=0:\n",
    "                    train_loss = cross_entropy.eval(session=sess, \n",
    "                            feed_dict={x:batch_test[0], y_: batch_test[1], keep_prob: 1.0})\n",
    "                    loss_valid = cross_entropy.eval(session=sess, \n",
    "                            feed_dict={x:X_valid, y_: y_valid, keep_prob: 1.0})\n",
    "                    train_accuracy = accuracy.eval(session=sess,\n",
    "                                feed_dict={x:batch_test[0], y_: batch_test[1], keep_prob: 1.0})\n",
    "                    valid_accuracy = accuracy.eval(session=sess, \n",
    "                                feed_dict={x:X_valid, y_: y_valid, keep_prob: 1.0})\n",
    "                    stats.append([global_step,train_loss, loss_valid, train_accuracy,valid_accuracy, speed])\n",
    "                    string = \"predict data: global_step %d, training/valid loss %.5g\\t%.5g; accuracy %.4g\\t%.4g; speed = %.4g lines/sec\"%(\n",
    "                            global_step, train_loss, loss_valid, train_accuracy, valid_accuracy, speed)\n",
    "                    send2telegramm(string)\n",
    "                    logger.info(string)\n",
    "\n",
    "                    saver.save(sess, join(dirname(model_path), 'with_pred/model'), \n",
    "                                    global_step=global_step)\n",
    "                    logger.info (\"predict data: global_step = {}, the model is saved\".format(global_step))\n",
    "                train_step.run(session=sess, \n",
    "                    feed_dict={x: batch_test[0], y_: batch_test[1], keep_prob: KEEP_PROB})\n",
    "                global_step += 1\n",
    "\n",
    "        if i % num_batches == 0:\n",
    "            saver.save(sess, model_path, global_step=global_step)\n",
    "            logger.info (\"global_step = {}, the model is saved\".format(global_step))\n",
    "        counter += 1\n",
    "        global_step += 1\n",
    "    \n",
    "    plot_chart(stats)\n",
    "\n",
    "    \n",
    "#plot chartsz\n",
    "#format: [i,average_loss, loss_valid, train_accuracy,valid_accuracy, speed]\n",
    "def plot_chart(stats):\n",
    "    plt.figure(figsize=(10,5))\n",
    "    steps = [a[0] for a in stats][1:]\n",
    "    train_acc = [a[3] for a in stats][1:]\n",
    "    test_acc = [a[4] for a in stats][1:]\n",
    "\n",
    "    plt.plot(steps,train_acc, label = \"train\", c='b')\n",
    "    plt.plot(steps,test_acc, label = \"test\", c='r')\n",
    "    plt.grid(True)\n",
    "    plt.title(\"accuracy VS step\", fontsize = 14)\n",
    "    plt.ylabel(\"accuracy\", fontsize = 13)\n",
    "    plt.xlabel(\"step\", fontsize = 13)\n",
    "    plt.legend()\n",
    "    plt.savefig('{}_figure.png'.format(model_path))\n",
    "\n",
    "    #save stats:\n",
    "    with open('{}_stats.txt'.format(model_path), 'w') as f:\n",
    "        string = [\"\\t\".join(map(str,el)) + \"\\n\" for el in stats]\n",
    "        f.writelines(string)\n",
    "\n",
    "if DO_TRAIN:\n",
    "    train()\n",
    "logger.info ('the training completed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PREDICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DO_CUSTOM_PREDICT:\n",
    "    config=tf.ConfigProto(\n",
    "            intra_op_parallelism_threads=0,\n",
    "            inter_op_parallelism_threads=0,\n",
    "            log_device_placement=True)\n",
    "    config.gpu_options.allow_growth = True\n",
    "\n",
    "    sess = tf.Session(graph=graph, config=config)\n",
    "    _ = sess.run(init)\n",
    "\n",
    "    saver.restore(sess, tf.train.latest_checkpoint(MODEL_PATH_CUSTOM_PREDICT))\n",
    "\n",
    "    \n",
    "    #predict by batch (without such trick, Memory Error raises):\n",
    "size = 200\n",
    "batches_generator = (x_test_to_submit[i:i + size] for i in range(0, len(x_test_to_submit), size))\n",
    "\n",
    "predictions = []\n",
    "confidences = []\n",
    "\n",
    "# silence processiong (!)\n",
    "# confusion matrix on train/test/predict data\n",
    "\n",
    "binary_target = y_conv\n",
    "confes = tf.reduce_max(tf.nn.softmax(binary_target), reduction_indices=[1])\n",
    "targets = tf.argmax(binary_target,1)\n",
    "\n",
    "for test_batch in tqdm(batches_generator, total = len(x_test_to_submit)//size):\n",
    "    targs = targets.eval(session = sess, feed_dict={x:test_batch, keep_prob: 1.0})\n",
    "    confs = confes.eval(session = sess, feed_dict={x:test_batch, keep_prob: 1.0})\n",
    "\n",
    "    labels = [map_dict_reverse[x] for x in targs.tolist()]\n",
    "    predictions.extend(labels)\n",
    "    confidences.extend(confs.tolist())\n",
    "    \n",
    "#filter unknown\n",
    "predictions_filtered = [x if x in to_keep else 'unknown' for x in predictions]\n",
    "user_names = df_predict.user_names.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process_silence\n",
    "\n",
    "df_predict = df_predict[:len(x_test_to_submit)]\n",
    "\n",
    "df_predict['preds'] = predictions_filtered\n",
    "df_predict['conf'] = confidences\n",
    "\n",
    "silence_threshold = 0.5\n",
    "df_predict.loc[:,'preds'] = df_predict.apply(lambda X: \n",
    "            'silence' if X.conf < silence_threshold else X.preds, axis = 1)\n",
    "\n",
    "df_predict.loc[:,'preds'] = df_predict.apply(lambda X: \n",
    "            'silence' if abs(X.avg_ampl) < 0.01 else X.preds, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "#df_predict.std_ampl.hist(bins = 100)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix = datetime.datetime.today().isoformat().split(':')[0]\n",
    "df_predict.to_csv('prediction_{}.txt'.format(suffix), sep=',',\n",
    "                  columns = ['user_names', 'preds'], index=False, \n",
    "                  header = ['fname','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#analysis\n",
    "df_to_analysis = df_predict[df_predict.conf < 0.3]\n",
    "df_to_analysis = df_predict[df_predict.preds == 'silence']\n",
    "\n",
    "for index, row in df_to_analysis.iterrows():\n",
    "    addr = row['train_names'] \n",
    "    print (row['preds'], row['conf'], row['avg_ampl'], row['std_ampl'])\n",
    "    ipd.display(ipd.Audio(addr, autoplay=True))\n",
    "    time.sleep(3)\n",
    "    ipd.clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*submission example*\n",
    "\n",
    "- fname,label\n",
    "- clip_000044442.wav,silence\n",
    "- clip_0000adecb.wav,silence\n",
    "- clip_0000d4322.wav,silence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save results\n",
    "suffix = datetime.datetime.today().isoformat().split(':')[0]\n",
    "with open('prediction_{}.txt'.format(suffix), 'w') as f:\n",
    "    f.write(\"fname,label\\n\")  #header\n",
    "    to_save = (\"{},{}\\n\".format(a,b) for a,b in zip(user_names, predictions_filtered))\n",
    "    f.writelines(to_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###### convert to .py script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbconvert --to script CNN.ipynb --output CNN_current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PREDICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dkuzin/apps/anaconda3/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import os.path\n",
    "import sys\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.contrib.framework.python.ops import audio_ops as contrib_audio\n",
    "import input_data\n",
    "import models\n",
    "from tensorflow.python.framework import graph_util\n",
    "\n",
    "from tqdm import tqdm\n",
    "from os.path import join, basename\n",
    "\n",
    "FLAGS = None\n",
    "\n",
    "\n",
    "\n",
    "WORKDIR = '/home/dkuzin/files/tensorflow_speech_recognition'\n",
    "\n",
    "train_audio_path = WORKDIR + '/train/audio/'\n",
    "test_audio_path = WORKDIR + '/test/audio/'\n",
    "to_keep = 'yes no up down left right on off stop go silence unknown'.split() \n",
    "test_names = [join(test_audio_path, f) for f in os.listdir(test_audio_path) \n",
    "                              if f.endswith('.wav')]\n",
    "user_names = [basename(f) for f in test_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [00:05, 1885.31it/s]\n"
     ]
    }
   ],
   "source": [
    "#upload_all_data\n",
    "num_files_DEBAG = 10000\n",
    "data = []\n",
    "for name, full_path in tqdm(zip(user_names, test_names[:num_files_DEBAG])):\n",
    "    with open(full_path, 'rb') as wav_file:\n",
    "        wav_data = wav_file.read()\n",
    "        data.append(wav_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_labels(filename):\n",
    "  \"\"\"Read in labels, one label per line.\"\"\"\n",
    "  return [line.rstrip() for line in tf.gfile.GFile(filename)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['_silence_', '_unknown_', 'yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go']\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = (\"/home/dkuzin/files/tensorflow_speech_recognition/\"\n",
    "            \"saved_models/conv3_labels.txt\")\n",
    "labels_list = load_labels(filename)\n",
    "str(labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FLAGS:\n",
    "    def __init__(self):\n",
    "        self.sample_rate = 16000\n",
    "        self.clip_duration_ms = 1000\n",
    "        self.clip_stride_ms = 30\n",
    "        self.window_size_ms = 30.\n",
    "        self.window_stride_ms = 10.\n",
    "        self.dct_coefficient_count = 40\n",
    "        self.start_checkpoint = (\n",
    "            \"/home/dkuzin/files/tensorflow_speech_recognition/\"\n",
    "            \"saved_models/conv.ckpt-9\")\n",
    "        self.model_architecture = 'conv'\n",
    "        self.wanted_words = 'yes,no,up,down,left,right,on,off,stop,go'\n",
    "        self.output_file = '/home/dkuzin/predictions/file_name.txt'\n",
    "FLAGS = FLAGS()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_inference_graph(wanted_words, sample_rate, clip_duration_ms,\n",
    "                           clip_stride_ms, window_size_ms, window_stride_ms,\n",
    "                           dct_coefficient_count, model_architecture):\n",
    "    \"\"\"Creates an audio model with the nodes needed for inference.\n",
    "\n",
    "    Uses the supplied arguments to create a model, and inserts the input and\n",
    "    output nodes that are needed to use the graph for inference.\n",
    "\n",
    "    Args:\n",
    "    wanted_words: Comma-separated list of the words we're trying to recognize.\n",
    "    sample_rate: How many samples per second are in the input audio files.\n",
    "    clip_duration_ms: How many samples to analyze for the audio pattern.\n",
    "    clip_stride_ms: How often to run recognition. Useful for models with cache.\n",
    "    window_size_ms: Time slice duration to estimate frequencies from.\n",
    "    window_stride_ms: How far apart time slices should be.\n",
    "    dct_coefficient_count: Number of frequency bands to analyze.\n",
    "    model_architecture: Name of the kind of model to generate.\n",
    "    \"\"\"\n",
    "    \n",
    "    graph = tf.Graph()\n",
    "    with graph.as_default():\n",
    "        words_list = input_data.prepare_words_list(wanted_words.split(','))\n",
    "        model_settings = models.prepare_model_settings(\n",
    "          len(words_list), sample_rate, clip_duration_ms, window_size_ms,\n",
    "          window_stride_ms, dct_coefficient_count)\n",
    "        runtime_settings = {'clip_stride_ms': clip_stride_ms}\n",
    "\n",
    "        wav_data_placeholder = tf.placeholder(\n",
    "                        tf.string, [], name='wav_data')\n",
    "        decoded_sample_data = contrib_audio.decode_wav(\n",
    "          wav_data_placeholder,\n",
    "          desired_channels=1,\n",
    "          desired_samples=model_settings['desired_samples'],\n",
    "          name='decoded_sample_data')\n",
    "        spectrogram = contrib_audio.audio_spectrogram(\n",
    "          decoded_sample_data.audio,\n",
    "          window_size=model_settings['window_size_samples'],\n",
    "          stride=model_settings['window_stride_samples'],\n",
    "          magnitude_squared=True)\n",
    "        fingerprint_input = contrib_audio.mfcc(\n",
    "          spectrogram,\n",
    "          decoded_sample_data.sample_rate,\n",
    "          dct_coefficient_count=dct_coefficient_count)\n",
    "        fingerprint_frequency_size = model_settings['dct_coefficient_count']\n",
    "        fingerprint_time_size = model_settings['spectrogram_length']\n",
    "        reshaped_input = tf.reshape(fingerprint_input, [\n",
    "          -1, fingerprint_time_size * fingerprint_frequency_size\n",
    "        ])\n",
    "\n",
    "        logits = models.create_model(\n",
    "          reshaped_input, model_settings, model_architecture, \n",
    "                    is_training=False, runtime_settings=runtime_settings)\n",
    "\n",
    "        # Create an output to use for inference.\n",
    "        tf.nn.softmax(logits, name='labels_softmax')\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr = create_inference_graph(\n",
    "    FLAGS.wanted_words, FLAGS.sample_rate,\n",
    "    FLAGS.clip_duration_ms, FLAGS.clip_stride_ms,\n",
    "    FLAGS.window_size_ms, FLAGS.window_stride_ms,\n",
    "    FLAGS.dct_coefficient_count, FLAGS.model_architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/dkuzin/files/tensorflow_speech_recognition/saved_models/conv.ckpt-9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [03:15<00:00, 51.08it/s]\n"
     ]
    }
   ],
   "source": [
    "config=tf.ConfigProto(\n",
    "        intra_op_parallelism_threads=0,\n",
    "        inter_op_parallelism_threads=0,\n",
    "        log_device_placement=True)\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "num_top_predictions = 3\n",
    "labels = labels_list\n",
    "\n",
    "with tf.Session(graph=gr, config=config) as sess:\n",
    "    models.load_variables_from_checkpoint(sess, FLAGS.start_checkpoint)\n",
    "    \n",
    "    tf.global_variables_initializer().run()\n",
    "    output_layer_name = \"labels_softmax:0\"\n",
    "    softmax_tensor = sess.graph.get_tensor_by_name(output_layer_name)\n",
    "    \n",
    "    res = []\n",
    "    for i, binary in tqdm(enumerate(data), total=len(data)):\n",
    "        predictions = sess.run(softmax_tensor, \n",
    "                            feed_dict={'wav_data:0': binary})\n",
    "        # Sort to show labels in order of confidence\n",
    "        imd_max = predictions[0].argmax()\n",
    "        human_string = labels[imd_max]\n",
    "        file_name = user_names[i]\n",
    "        score = predictions[0][imd_max]\n",
    "        res.append((file_name, human_string, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "df = pd.DataFrame(res, columns = ['name','pred','score'])\n",
    "df.loc[:,'pred'] = df.pred.apply(lambda x: x.strip('_'))\n",
    "\n",
    "suffix = datetime.datetime.today().isoformat().split(':')[0]\n",
    "df.to_csv('prediction_{}.txt'.format(suffix), sep=',',\n",
    "                  columns = ['name', 'pred'], index=False, \n",
    "                  header = ['fname','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.08642657,  0.07290708,  0.06629921,  0.06999502,  0.07187109,\n",
       "        0.07884863,  0.10164592,  0.11838709,  0.07807236,  0.08114801,\n",
       "        0.09346082,  0.08093826], dtype=float32)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('clip_1ba25f2c9.wav', 'right', 0.14234568)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>pred</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>clip_1ba25f2c9.wav</td>\n",
       "      <td>right</td>\n",
       "      <td>0.142346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>clip_6dc264aa2.wav</td>\n",
       "      <td>right</td>\n",
       "      <td>0.106400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>clip_bfcfceed4.wav</td>\n",
       "      <td>right</td>\n",
       "      <td>0.104031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>clip_836995727.wav</td>\n",
       "      <td>right</td>\n",
       "      <td>0.136066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>clip_04de60133.wav</td>\n",
       "      <td>right</td>\n",
       "      <td>0.108207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>clip_fa6dfdac0.wav</td>\n",
       "      <td>right</td>\n",
       "      <td>0.149808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>clip_0744e60bf.wav</td>\n",
       "      <td>right</td>\n",
       "      <td>0.108025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>clip_4836e2033.wav</td>\n",
       "      <td>right</td>\n",
       "      <td>0.113236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>clip_89872a949.wav</td>\n",
       "      <td>right</td>\n",
       "      <td>0.107450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>clip_cbd72436c.wav</td>\n",
       "      <td>right</td>\n",
       "      <td>0.119308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>clip_8501517e0.wav</td>\n",
       "      <td>right</td>\n",
       "      <td>0.100799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>clip_07df6f920.wav</td>\n",
       "      <td>right</td>\n",
       "      <td>0.104804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>clip_58efe2902.wav</td>\n",
       "      <td>right</td>\n",
       "      <td>0.104540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>clip_c1a3dfe1c.wav</td>\n",
       "      <td>right</td>\n",
       "      <td>0.104417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>clip_db888d393.wav</td>\n",
       "      <td>right</td>\n",
       "      <td>0.155743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>clip_0ad3ff22e.wav</td>\n",
       "      <td>right</td>\n",
       "      <td>0.119710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>clip_206a2b5c4.wav</td>\n",
       "      <td>right</td>\n",
       "      <td>0.103400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>clip_69920c898.wav</td>\n",
       "      <td>silence</td>\n",
       "      <td>0.099175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>clip_fec307a92.wav</td>\n",
       "      <td>right</td>\n",
       "      <td>0.108445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>clip_fda8aee4f.wav</td>\n",
       "      <td>right</td>\n",
       "      <td>0.113712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>clip_d67ca908d.wav</td>\n",
       "      <td>left</td>\n",
       "      <td>0.105788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>clip_60f064852.wav</td>\n",
       "      <td>right</td>\n",
       "      <td>0.140779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>clip_3b967bf5a.wav</td>\n",
       "      <td>right</td>\n",
       "      <td>0.183308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>clip_e02864a7e.wav</td>\n",
       "      <td>left</td>\n",
       "      <td>0.093607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>clip_37d27a026.wav</td>\n",
       "      <td>right</td>\n",
       "      <td>0.097957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>clip_3a2af6a97.wav</td>\n",
       "      <td>right</td>\n",
       "      <td>0.133703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>clip_049a584af.wav</td>\n",
       "      <td>right</td>\n",
       "      <td>0.115635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>clip_03e087ee5.wav</td>\n",
       "      <td>right</td>\n",
       "      <td>0.106313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>clip_dd7ecc13d.wav</td>\n",
       "      <td>right</td>\n",
       "      <td>0.103576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>clip_75e32e343.wav</td>\n",
       "      <td>right</td>\n",
       "      <td>0.114878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9970</th>\n",
       "      <td>clip_e177b1569.wav</td>\n",
       "      <td>silence</td>\n",
       "      <td>0.107098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9971</th>\n",
       "      <td>clip_ef831e0ca.wav</td>\n",
       "      <td>right</td>\n",
       "      <td>0.110999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9972</th>\n",
       "      <td>clip_9fb33f250.wav</td>\n",
       "      <td>right</td>\n",
       "      <td>0.137210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9973</th>\n",
       "      <td>clip_d5c88fcaa.wav</td>\n",
       "      <td>right</td>\n",
       "      <td>0.118558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9974</th>\n",
       "      <td>clip_9df9d0f91.wav</td>\n",
       "      <td>right</td>\n",
       "      <td>0.111398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9975</th>\n",
       "      <td>clip_4dbeb6538.wav</td>\n",
       "      <td>right</td>\n",
       "      <td>0.101969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9976</th>\n",
       "      <td>clip_f0cc6ff26.wav</td>\n",
       "      <td>right</td>\n",
       "      <td>0.179050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9977</th>\n",
       "      <td>clip_7c5afb998.wav</td>\n",
       "      <td>right</td>\n",
       "      <td>0.607799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9978</th>\n",
       "      <td>clip_6e6e074e7.wav</td>\n",
       "      <td>right</td>\n",
       "      <td>0.128595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9979</th>\n",
       "      <td>clip_8251e1f89.wav</td>\n",
       "      <td>right</td>\n",
       "      <td>0.112012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9980</th>\n",
       "      <td>clip_688ac9eeb.wav</td>\n",
       "      <td>right</td>\n",
       "      <td>0.104075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9981</th>\n",
       "      <td>clip_bbb84d15c.wav</td>\n",
       "      <td>right</td>\n",
       "      <td>0.109177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9982</th>\n",
       "      <td>clip_1a18c03b3.wav</td>\n",
       "      <td>left</td>\n",
       "      <td>0.094986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9983</th>\n",
       "      <td>clip_2d6826dfd.wav</td>\n",
       "      <td>go</td>\n",
       "      <td>0.095415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9984</th>\n",
       "      <td>clip_062c7ef8a.wav</td>\n",
       "      <td>off</td>\n",
       "      <td>0.099951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9985</th>\n",
       "      <td>clip_c21540f95.wav</td>\n",
       "      <td>right</td>\n",
       "      <td>0.183159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9986</th>\n",
       "      <td>clip_63e36c8eb.wav</td>\n",
       "      <td>left</td>\n",
       "      <td>0.110231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9987</th>\n",
       "      <td>clip_dec40874d.wav</td>\n",
       "      <td>silence</td>\n",
       "      <td>0.102892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9988</th>\n",
       "      <td>clip_b07242a52.wav</td>\n",
       "      <td>right</td>\n",
       "      <td>0.126934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9989</th>\n",
       "      <td>clip_df7136d60.wav</td>\n",
       "      <td>right</td>\n",
       "      <td>0.113555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9990</th>\n",
       "      <td>clip_9ba68d0c8.wav</td>\n",
       "      <td>right</td>\n",
       "      <td>0.183766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9991</th>\n",
       "      <td>clip_a81a92403.wav</td>\n",
       "      <td>stop</td>\n",
       "      <td>0.097108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9992</th>\n",
       "      <td>clip_6724db6f0.wav</td>\n",
       "      <td>right</td>\n",
       "      <td>0.102153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9993</th>\n",
       "      <td>clip_a9cc8fb9b.wav</td>\n",
       "      <td>right</td>\n",
       "      <td>0.117115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9994</th>\n",
       "      <td>clip_a8fa8a5f3.wav</td>\n",
       "      <td>right</td>\n",
       "      <td>0.182248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>clip_9236a6e0b.wav</td>\n",
       "      <td>right</td>\n",
       "      <td>0.126961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>clip_b186fad3f.wav</td>\n",
       "      <td>right</td>\n",
       "      <td>0.111041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>clip_469b92390.wav</td>\n",
       "      <td>right</td>\n",
       "      <td>0.117492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>clip_ff9d51796.wav</td>\n",
       "      <td>right</td>\n",
       "      <td>0.123054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>clip_e857c5709.wav</td>\n",
       "      <td>right</td>\n",
       "      <td>0.118387</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    name     pred     score\n",
       "0     clip_1ba25f2c9.wav    right  0.142346\n",
       "1     clip_6dc264aa2.wav    right  0.106400\n",
       "2     clip_bfcfceed4.wav    right  0.104031\n",
       "3     clip_836995727.wav    right  0.136066\n",
       "4     clip_04de60133.wav    right  0.108207\n",
       "5     clip_fa6dfdac0.wav    right  0.149808\n",
       "6     clip_0744e60bf.wav    right  0.108025\n",
       "7     clip_4836e2033.wav    right  0.113236\n",
       "8     clip_89872a949.wav    right  0.107450\n",
       "9     clip_cbd72436c.wav    right  0.119308\n",
       "10    clip_8501517e0.wav    right  0.100799\n",
       "11    clip_07df6f920.wav    right  0.104804\n",
       "12    clip_58efe2902.wav    right  0.104540\n",
       "13    clip_c1a3dfe1c.wav    right  0.104417\n",
       "14    clip_db888d393.wav    right  0.155743\n",
       "15    clip_0ad3ff22e.wav    right  0.119710\n",
       "16    clip_206a2b5c4.wav    right  0.103400\n",
       "17    clip_69920c898.wav  silence  0.099175\n",
       "18    clip_fec307a92.wav    right  0.108445\n",
       "19    clip_fda8aee4f.wav    right  0.113712\n",
       "20    clip_d67ca908d.wav     left  0.105788\n",
       "21    clip_60f064852.wav    right  0.140779\n",
       "22    clip_3b967bf5a.wav    right  0.183308\n",
       "23    clip_e02864a7e.wav     left  0.093607\n",
       "24    clip_37d27a026.wav    right  0.097957\n",
       "25    clip_3a2af6a97.wav    right  0.133703\n",
       "26    clip_049a584af.wav    right  0.115635\n",
       "27    clip_03e087ee5.wav    right  0.106313\n",
       "28    clip_dd7ecc13d.wav    right  0.103576\n",
       "29    clip_75e32e343.wav    right  0.114878\n",
       "...                  ...      ...       ...\n",
       "9970  clip_e177b1569.wav  silence  0.107098\n",
       "9971  clip_ef831e0ca.wav    right  0.110999\n",
       "9972  clip_9fb33f250.wav    right  0.137210\n",
       "9973  clip_d5c88fcaa.wav    right  0.118558\n",
       "9974  clip_9df9d0f91.wav    right  0.111398\n",
       "9975  clip_4dbeb6538.wav    right  0.101969\n",
       "9976  clip_f0cc6ff26.wav    right  0.179050\n",
       "9977  clip_7c5afb998.wav    right  0.607799\n",
       "9978  clip_6e6e074e7.wav    right  0.128595\n",
       "9979  clip_8251e1f89.wav    right  0.112012\n",
       "9980  clip_688ac9eeb.wav    right  0.104075\n",
       "9981  clip_bbb84d15c.wav    right  0.109177\n",
       "9982  clip_1a18c03b3.wav     left  0.094986\n",
       "9983  clip_2d6826dfd.wav       go  0.095415\n",
       "9984  clip_062c7ef8a.wav      off  0.099951\n",
       "9985  clip_c21540f95.wav    right  0.183159\n",
       "9986  clip_63e36c8eb.wav     left  0.110231\n",
       "9987  clip_dec40874d.wav  silence  0.102892\n",
       "9988  clip_b07242a52.wav    right  0.126934\n",
       "9989  clip_df7136d60.wav    right  0.113555\n",
       "9990  clip_9ba68d0c8.wav    right  0.183766\n",
       "9991  clip_a81a92403.wav     stop  0.097108\n",
       "9992  clip_6724db6f0.wav    right  0.102153\n",
       "9993  clip_a9cc8fb9b.wav    right  0.117115\n",
       "9994  clip_a8fa8a5f3.wav    right  0.182248\n",
       "9995  clip_9236a6e0b.wav    right  0.126961\n",
       "9996  clip_b186fad3f.wav    right  0.111041\n",
       "9997  clip_469b92390.wav    right  0.117492\n",
       "9998  clip_ff9d51796.wav    right  0.123054\n",
       "9999  clip_e857c5709.wav    right  0.118387\n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "a =  \"\"\"  [[130   0   0   0   0   0   0   0   0   0   0   0]\n",
    " [  1  97   5   2   0   7   2   6   5   0   1   4]\n",
    " [  3   1 124   2   0   1   2   0   0   0   0   0]\n",
    " [  0   2   3 127   0   2   1   0   0   0   0   5]\n",
    " [  2   0   0   0 119   0   0   0   0   1   3   1]\n",
    " [  0   1   0   3   0 122   0   0   0   0   2   0]\n",
    " [  1   0   4   0   1   0 114   2   0   0   0   0]\n",
    " [  0   2   0   0   1   0   2 128   0   0   0   0]\n",
    " [  3   2   0   0   1   0   0   0 123   0   0   0]\n",
    " [  0   0   0   0   6   0   2   0   2 121   1   0]\n",
    " [  2   0   0   0   3   0   0   0   0   1 120   1]\n",
    " [  3   5   0  13   1   8   0   1   0   1   1  90]]\n",
    "\"\"\"\n",
    "\n",
    "l = eval(a.strip().replace('\\n', ',').replace(' ',',').\n",
    "         replace(',,',',').replace(',,',',').replace(',,',',').\n",
    "         replace(',,',',').replace('[,','['))\n",
    "\n",
    "default = 'yes,no,up,down,left,right,on,off,stop,go'.split(',')\n",
    "default =  ['silence', 'unknown'] + default\n",
    "\n",
    "\n",
    "array = l\n",
    "df_cm = pd.DataFrame(array, index = default, columns = default)\n",
    "_ = plt.figure(figsize = (11,10))\n",
    "sns.heatmap(df_cm, annot=True, fmt='.0f', \n",
    "            linewidths=0.01)\n",
    "plt.xticks(rotation=90)\n",
    "plt.yticks(rotation=0)\n",
    "plt.xlabel('predict', size = 15)\n",
    "plt.ylabel('actual', size = 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAowAAAJvCAYAAADx44D6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nERERafV/AXnqYkdqSFoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdde315d2b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "a =  \"\"\"  [[129   0   0   0   0   0   0   0   0   0   0   0]\n",
    " [  2  91   1   1   2   7   4   1   8   2   2   8]\n",
    " [  0   1 122   1   0   2   1   1   0   0   0   0]\n",
    " [  0   6   2 105   2   0   2   0   0   0   1  12]\n",
    " [  2   3   0   0 118   0   2   2   0   5   2   0]\n",
    " [  1   3   1  12   0 109   0   0   0   0   1   9]\n",
    " [  0   1   8   2   0   0 111   3   0   0   0   0]\n",
    " [  0   5   0   1   1   0   3 112   1   0   0   0]\n",
    " [  1   3   0   0   2   1   0   0 116   4   0   1]\n",
    " [  1   1   0   0  16   0   1   1   2 101   0   1]\n",
    " [  0   3   0   1   8   4   2   0   0   1  99   1]\n",
    " [  5   2   0   5   0   2   1   1   0   2   0 119]]\"\"\"\n",
    "\n",
    "l = eval(a.strip().replace('\\n', ',').replace(' ',',').\n",
    "         replace(',,',',').replace(',,',',').replace(',,',',').\n",
    "         replace(',,',',').replace('[,','['))\n",
    "\n",
    "default = 'yes,no,up,down,left,right,on,off,stop,go'.split(',')\n",
    "default =  ['silence', 'unknown'] + default\n",
    "\n",
    "\n",
    "array = l\n",
    "df_cm = pd.DataFrame(array, index = default, columns = default)\n",
    "_ = plt.figure(figsize = (11,10))\n",
    "sns.heatmap(df_cm, annot=True, fmt='.0f', \n",
    "            linewidths=0.01)\n",
    "plt.xticks(rotation=90)\n",
    "plt.yticks(rotation=0)\n",
    "plt.xlabel('predict', size = 15)\n",
    "plt.ylabel('actual', size = 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dkuzin/apps/anaconda3/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import os.path\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "from six.moves import xrange\n",
    "import tensorflow as tf\n",
    "\n",
    "import input_data\n",
    "import models\n",
    "from tensorflow.python.platform import gfile\n",
    "\n",
    "FLAGS = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FLAGS:\n",
    "    def __init__(self):\n",
    "        self.data_dir = \"/home/dkuzin/files/tensorflow_speech_recognition/train/audio\"\n",
    "        self.testing_percentage = 5\n",
    "        self.validation_percentage = 5\n",
    "        self.how_many_training_steps = \"15000,25000,25000\"\n",
    "        self.learning_rate = \"0.001,0.0001,0.00001\"\n",
    "        self.batch_size = 200\n",
    "        self.eval_step_interval = 400\n",
    "        self.train_dir = \"/home/dkuzin/files/tensorflow_speech_recognition/saved_models/calc_test\"\n",
    "        self.save_step_interval = 400\n",
    "        self.model_architecture = \"conv\"\n",
    "        self.summaries_dir = \"/home/dkuzin/files/tensorflow_speech_recognition/board\"\n",
    "        self.data_url = 'http://download.tensorflow.org/data/speech_commands_v0.01.tar.gz'\n",
    "        self.silence_percentage = 10.\n",
    "        self.unknown_percentage = 10.\n",
    "        self.wanted_words = 'yes,no,up,down,left,right,on,off,stop,go'\n",
    "        self.sample_rate = 16000\n",
    "        self.clip_duration_ms = 1000\n",
    "        self.window_size_ms = 30.\n",
    "        self.window_stride_ms = 10.\n",
    "        self.dct_coefficient_count = 40\n",
    "        self.data_dir = \"/home/dkuzin/files/tensorflow_speech_recognition/train/audio/\"\n",
    "        self.background_frequency = 0.8\n",
    "        self.background_volume = 0.1\n",
    "        self.time_shift_ms = 100\n",
    "        self.predict_dir = '/home/dkuzin/files/tensorflow_speech_recognition/test/audio'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAGS = FLAGS()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_settings = models.prepare_model_settings(\n",
    "      len(input_data.prepare_words_list(FLAGS.wanted_words.split(','))),\n",
    "      FLAGS.sample_rate, FLAGS.clip_duration_ms, FLAGS.window_size_ms,\n",
    "      FLAGS.window_stride_ms, FLAGS.dct_coefficient_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:I ve found 158538 files for prediction\n"
     ]
    }
   ],
   "source": [
    "audio_processor = input_data.AudioProcessor(\n",
    "      FLAGS.data_url, FLAGS.data_dir, FLAGS.silence_percentage,\n",
    "      FLAGS.unknown_percentage,\n",
    "      FLAGS.wanted_words.split(','), FLAGS.validation_percentage,\n",
    "      FLAGS.testing_percentage, model_settings, predict_dir=FLAGS.predict_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_shift_samples = int((FLAGS.time_shift_ms * FLAGS.sample_rate) / 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto(log_device_placement=True,\n",
    "          intra_op_parallelism_threads=0, inter_op_parallelism_threads=0)\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fingerprints, train_ground_truth = audio_processor.get_data(\n",
    "        3000, 0, model_settings, FLAGS.background_frequency,\n",
    "        FLAGS.background_volume, time_shift_samples, 'training', sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file': '/home/dkuzin/files/tensorflow_speech_recognition/train/audio/go/10ace7eb_nohash_0.wav',\n",
       " 'label': 'go'}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_processor.data_index['training'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_processor.data_index['predict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_path = os.path.join(FLAGS.predict_dir, '*.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/dkuzin/files/tensorflow_speech_recognition/test/audio/*.wav'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_silence_',\n",
       " '_unknown_',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'up',\n",
       " 'down',\n",
       " 'left',\n",
       " 'right',\n",
       " 'on',\n",
       " 'off',\n",
       " 'stop',\n",
       " 'go']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_processor.words_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
